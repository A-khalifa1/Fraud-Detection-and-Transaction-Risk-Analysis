# ğŸš€ Fraud Detection & Transaction Risk Analysis

## ğŸ” Overview
This project builds a **fraud detection & transaction risk analysis pipeline** for a **digital wallet system**.  
It leverages a **Star Schema** to structure transaction data efficiently for analytical processing.  

The ETL pipeline extracts, transforms, and loads (ETL) transaction data while ensuring **high performance & integrity**.  

![ELT Pipeline](Fraud-Detection-and-Transaction-Risk-Analysis.jpg)

## ğŸ“Š Data Model â€“ Star Schema
The project follows a **Star Schema** for optimized storage & analytics.

![Schema](star_schema_pure.png)

### ğŸ¦ **Fact Table: `Fact_Transactions`**
> Stores core transaction details & links to multiple dimensions.

| Column | Type | Description |
|---------|------|-------------|
| `transaction_sk` | PK | Unique transaction key |
| `customer_sk` | FK | Links to customers |
| `merchant_sk` | FK | Links to merchants |
| `time_sk` | FK | Links to time table |
| `device_sk` | FK | Links to device info |
| `location_sk` | FK | Geographical location |
| `transaction_amount` | NUMERIC | Amount transacted |
| `isfraud` | BOOLEAN | Fraud flag |
| `isflaggedfraud` | BOOLEAN | Flagged fraud status |

### ğŸ·ï¸ **Dimension Tables**
#### ğŸ“† `Dim_Time` â€“ Stores transaction timestamps  
- `time_sk` (PK) ğŸ—ï¸  
- `date_bk`, `hour_bk`, `month`, `dayofweek`, `is_holiday`  

#### ğŸ‘¤ `Dim_Customer` â€“ Customer details  
- `customer_sk` (PK) ğŸ—ï¸  
- `full_name`, `contact_number`, `age`, `city`, `country`  

#### ğŸ¬ `Dim_Merchant` â€“ Merchant information  
- `merchant_sk` (PK) ğŸ—ï¸  
- `merchant_name`, `category`, `rating`, `location`  

#### ğŸ“± `Dim_Device` â€“ Device & OS details  
- `device_sk` (PK) ğŸ—ï¸  
- `device_type`, `operating_system`, `app_version`  

#### ğŸ“ `Dim_Location` â€“ Geographical data  
- `location_sk` (PK) ğŸ—ï¸  
- `city`, `region`, `latitude`, `longitude`  

#### ğŸ’³ `Dim_Transaction_Type` â€“ Payment type details  
- `transaction_type_sk` (PK) ğŸ—ï¸  
- `payment_channel_bk`, `type_bk`  

---

## âš™ï¸ **Data Pipeline Architecture**  
Follows a structured **ELT (Extract, Load, Transform) pipeline**.  

### ğŸ› ï¸ **Tech Stack**  
âœ… **Python & Pandas** â€“ Data processing & transformation  
âœ… **MongoDB** â€“ NoSQL database for raw storage  
âœ… **Airbyte** â€“ Extracts & loads data into PostgreSQL  
âœ… **PostgreSQL** â€“ Data warehouse for analytics  
âœ… **dbt** â€“ Data modeling & transformations  
âœ… **Kestra** â€“ Workflow orchestration  

### ğŸ”„ **Data Flow**  
1ï¸âƒ£ **CSV â†’ JSON & MongoDB** ğŸ“¥  
   - Convert raw transactions into JSON  
   - Insert into **MongoDB**  

2ï¸âƒ£ **MongoDB â†’ PostgreSQL (Staging)** ğŸ›¢ï¸  
   - **Airbyte** extracts & loads raw data  

3ï¸âƒ£ **PostgreSQL â†’ Data Warehouse** ğŸ¯  
   - **dbt** transforms data into a **star schema**  

4ï¸âƒ£ **Orchestration with Kestra** ğŸ¤–  
   - Automates the full pipeline  

---

## ğŸš€ **Running the Pipeline**  
### âœ… **Prerequisites**  
Install the required tools:  
```bash
pip install pandas pymongo
# Install MongoDB, PostgreSQL, Airbyte, dbt, and Kestra
```  

### ğŸ”§ **Execution Steps**  
1ï¸âƒ£ **Load Data into MongoDB**  
```bash
python convert_to_json_connect_mongo.ipynb
```  
2ï¸âƒ£ **Run Airbyte to transfer data from MongoDB to PostgreSQL**  
3ï¸âƒ£ **Execute dbt transformations**  
```bash
dbt run
```  
4ï¸âƒ£ **Use Kestra for orchestration**  

---  

## ğŸš€ **Future Enhancements**  
âœ… Implement **incremental loading** for optimized performance  
âœ… Enhance **data validation & cleansing** before insertion  
âœ… Integrate **real-time fraud detection** with streaming tech  

---  
**ğŸ“Œ Author:** Abdulrhman Khalifa  

ğŸ”— LinkedIn: [https://www.linkedin.com/in/abdulrahman-m-khalifa/](#)  

---  

ğŸ¯ **Built for fraud prevention. Powered by data.** ğŸ’¡  
